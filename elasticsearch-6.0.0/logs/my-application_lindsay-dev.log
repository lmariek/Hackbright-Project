[2017-12-05T06:34:25,945][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopping ...
[2017-12-05T06:34:26,039][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopped
[2017-12-05T06:34:26,040][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closing ...
[2017-12-05T06:34:26,078][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closed
[2017-12-05T20:08:28,619][WARN ][o.e.b.JNANatives         ] Unable to lock JVM Memory: error=12, reason=Cannot allocate memory
[2017-12-05T20:08:28,646][WARN ][o.e.b.JNANatives         ] This can result in part of the JVM being swapped out.
[2017-12-05T20:08:28,647][WARN ][o.e.b.JNANatives         ] Increase RLIMIT_MEMLOCK, soft limit: 65536, hard limit: 65536
[2017-12-05T20:08:28,648][WARN ][o.e.b.JNANatives         ] These can be adjusted by modifying /etc/security/limits.conf, for example: 
	# allow user 'vagrant' mlockall
	vagrant soft memlock unlimited
	vagrant hard memlock unlimited
[2017-12-05T20:08:28,648][WARN ][o.e.b.JNANatives         ] If you are logged in interactively, you will have to re-login for the new limits to take effect.
[2017-12-05T20:08:29,759][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initializing ...
[2017-12-05T20:08:30,002][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] using [1] data paths, mounts [[/home/vagrant/src (home_vagrant_src)]], net usable_space [291.3gb], net total_space [464.7gb], types [vboxsf]
[2017-12-05T20:08:30,004][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] heap size [1015.6mb], compressed ordinary object pointers [true]
[2017-12-05T20:08:30,362][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] node name [node-1_lindsay_01-dev], node ID [K6il1mL8SgO_OsMykcPBjA]
[2017-12-05T20:08:30,363][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] version[6.0.0], pid[5756], build[8f0685b/2017-11-10T18:41:22.859Z], OS[Linux/4.4.0-92-generic/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_151/25.151-b12]
[2017-12-05T20:08:30,363][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0, -Des.path.conf=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0/config]
[2017-12-05T20:08:35,940][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [aggs-matrix-stats]
[2017-12-05T20:08:35,942][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [analysis-common]
[2017-12-05T20:08:35,943][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [ingest-common]
[2017-12-05T20:08:35,943][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-expression]
[2017-12-05T20:08:35,944][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-mustache]
[2017-12-05T20:08:35,944][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-painless]
[2017-12-05T20:08:35,945][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [parent-join]
[2017-12-05T20:08:35,945][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [percolator]
[2017-12-05T20:08:35,946][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [reindex]
[2017-12-05T20:08:35,948][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [repository-url]
[2017-12-05T20:08:35,951][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [transport-netty4]
[2017-12-05T20:08:35,951][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [tribe]
[2017-12-05T20:08:35,952][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded plugin [ingest-attachment]
[2017-12-05T20:08:39,847][INFO ][o.e.d.DiscoveryModule    ] [node-1_lindsay_01-dev] using discovery type [zen]
[2017-12-05T20:08:41,149][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initialized
[2017-12-05T20:08:41,150][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] starting ...
[2017-12-05T20:08:41,645][INFO ][o.e.t.TransportService   ] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2017-12-05T20:08:41,712][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] memory locking requested for elasticsearch process but memory is not locked
[2017-12-05T20:08:41,713][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max number of threads [3811] for user [vagrant] is too low, increase to at least [4096]
[2017-12-05T20:08:41,715][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
[2017-12-05T20:08:44,805][INFO ][o.e.c.s.MasterService    ] [node-1_lindsay_01-dev] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Jwhi1JLPQwiVgvvQReI9VA}{127.0.0.1}{127.0.0.1:9300}
[2017-12-05T20:08:44,815][INFO ][o.e.c.s.ClusterApplierService] [node-1_lindsay_01-dev] new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Jwhi1JLPQwiVgvvQReI9VA}{127.0.0.1}{127.0.0.1:9300}, reason: apply cluster state (from master [master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Jwhi1JLPQwiVgvvQReI9VA}{127.0.0.1}{127.0.0.1:9300} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
[2017-12-05T20:08:44,855][INFO ][o.e.h.n.Netty4HttpServerTransport] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2017-12-05T20:08:44,856][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] started
[2017-12-05T20:08:45,434][INFO ][o.e.g.GatewayService     ] [node-1_lindsay_01-dev] recovered [1] indices into cluster_state
[2017-12-05T20:08:46,916][INFO ][o.e.c.r.a.AllocationService] [node-1_lindsay_01-dev] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[documents][3]] ...]).
[2017-12-05T20:35:52,050][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopping ...
[2017-12-05T20:35:52,096][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopped
[2017-12-05T20:35:52,097][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closing ...
[2017-12-05T20:35:52,111][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closed
[2017-12-05T20:36:29,069][WARN ][o.e.b.JNANatives         ] Unable to lock JVM Memory: error=12, reason=Cannot allocate memory
[2017-12-05T20:36:29,189][WARN ][o.e.b.JNANatives         ] This can result in part of the JVM being swapped out.
[2017-12-05T20:36:29,191][WARN ][o.e.b.JNANatives         ] Increase RLIMIT_MEMLOCK, soft limit: 65536, hard limit: 65536
[2017-12-05T20:36:29,192][WARN ][o.e.b.JNANatives         ] These can be adjusted by modifying /etc/security/limits.conf, for example: 
	# allow user 'vagrant' mlockall
	vagrant soft memlock unlimited
	vagrant hard memlock unlimited
[2017-12-05T20:36:29,193][WARN ][o.e.b.JNANatives         ] If you are logged in interactively, you will have to re-login for the new limits to take effect.
[2017-12-05T20:36:30,378][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initializing ...
[2017-12-05T20:36:30,642][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] using [1] data paths, mounts [[/home/vagrant/src (home_vagrant_src)]], net usable_space [292.3gb], net total_space [464.7gb], types [vboxsf]
[2017-12-05T20:36:30,644][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] heap size [1015.6mb], compressed ordinary object pointers [true]
[2017-12-05T20:36:31,125][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] node name [node-1_lindsay_01-dev], node ID [K6il1mL8SgO_OsMykcPBjA]
[2017-12-05T20:36:31,126][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] version[6.0.0], pid[6040], build[8f0685b/2017-11-10T18:41:22.859Z], OS[Linux/4.4.0-92-generic/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_151/25.151-b12]
[2017-12-05T20:36:31,127][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0, -Des.path.conf=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0/config]
[2017-12-05T20:36:36,753][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [aggs-matrix-stats]
[2017-12-05T20:36:36,754][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [analysis-common]
[2017-12-05T20:36:36,755][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [ingest-common]
[2017-12-05T20:36:36,756][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-expression]
[2017-12-05T20:36:36,756][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-mustache]
[2017-12-05T20:36:36,757][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-painless]
[2017-12-05T20:36:36,758][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [parent-join]
[2017-12-05T20:36:36,759][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [percolator]
[2017-12-05T20:36:36,759][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [reindex]
[2017-12-05T20:36:36,760][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [repository-url]
[2017-12-05T20:36:36,762][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [transport-netty4]
[2017-12-05T20:36:36,762][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [tribe]
[2017-12-05T20:36:36,765][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded plugin [ingest-attachment]
[2017-12-05T20:36:40,719][INFO ][o.e.d.DiscoveryModule    ] [node-1_lindsay_01-dev] using discovery type [zen]
[2017-12-05T20:36:42,385][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initialized
[2017-12-05T20:36:42,386][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] starting ...
[2017-12-05T20:36:42,869][INFO ][o.e.t.TransportService   ] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2017-12-05T20:36:42,974][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] memory locking requested for elasticsearch process but memory is not locked
[2017-12-05T20:36:42,979][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max number of threads [3811] for user [vagrant] is too low, increase to at least [4096]
[2017-12-05T20:36:42,981][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
[2017-12-05T20:36:46,128][INFO ][o.e.c.s.MasterService    ] [node-1_lindsay_01-dev] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{qBGou7reTVmnwPOmv2REAg}{127.0.0.1}{127.0.0.1:9300}
[2017-12-05T20:36:46,139][INFO ][o.e.c.s.ClusterApplierService] [node-1_lindsay_01-dev] new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{qBGou7reTVmnwPOmv2REAg}{127.0.0.1}{127.0.0.1:9300}, reason: apply cluster state (from master [master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{qBGou7reTVmnwPOmv2REAg}{127.0.0.1}{127.0.0.1:9300} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
[2017-12-05T20:36:46,178][INFO ][o.e.h.n.Netty4HttpServerTransport] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2017-12-05T20:36:46,180][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] started
[2017-12-05T20:36:46,704][INFO ][o.e.g.GatewayService     ] [node-1_lindsay_01-dev] recovered [1] indices into cluster_state
[2017-12-05T20:36:48,675][INFO ][o.e.c.r.a.AllocationService] [node-1_lindsay_01-dev] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[documents][1]] ...]).
