[2017-12-02T01:01:09,345][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopping ...
[2017-12-02T01:01:09,473][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] stopped
[2017-12-02T01:01:09,474][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closing ...
[2017-12-02T01:01:09,494][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] closed
[2017-12-02T20:41:35,171][WARN ][o.e.b.JNANatives         ] Unable to lock JVM Memory: error=12, reason=Cannot allocate memory
[2017-12-02T20:41:35,191][WARN ][o.e.b.JNANatives         ] This can result in part of the JVM being swapped out.
[2017-12-02T20:41:35,192][WARN ][o.e.b.JNANatives         ] Increase RLIMIT_MEMLOCK, soft limit: 65536, hard limit: 65536
[2017-12-02T20:41:35,193][WARN ][o.e.b.JNANatives         ] These can be adjusted by modifying /etc/security/limits.conf, for example: 
	# allow user 'vagrant' mlockall
	vagrant soft memlock unlimited
	vagrant hard memlock unlimited
[2017-12-02T20:41:35,194][WARN ][o.e.b.JNANatives         ] If you are logged in interactively, you will have to re-login for the new limits to take effect.
[2017-12-02T20:41:36,342][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initializing ...
[2017-12-02T20:41:36,618][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] using [1] data paths, mounts [[/home/vagrant/src (home_vagrant_src)]], net usable_space [291gb], net total_space [464.7gb], types [vboxsf]
[2017-12-02T20:41:36,620][INFO ][o.e.e.NodeEnvironment    ] [node-1_lindsay_01-dev] heap size [1015.6mb], compressed ordinary object pointers [true]
[2017-12-02T20:41:37,109][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] node name [node-1_lindsay_01-dev], node ID [K6il1mL8SgO_OsMykcPBjA]
[2017-12-02T20:41:37,114][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] version[6.0.0], pid[32627], build[8f0685b/2017-11-10T18:41:22.859Z], OS[Linux/4.4.0-92-generic/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_151/25.151-b12]
[2017-12-02T20:41:37,116][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] JVM arguments [-Xms1g, -Xmx1g, -XX:+UseConcMarkSweepGC, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:+AlwaysPreTouch, -Xss1m, -Djava.awt.headless=true, -Dfile.encoding=UTF-8, -Djna.nosys=true, -XX:-OmitStackTraceInFastThrow, -Dio.netty.noUnsafe=true, -Dio.netty.noKeySetOptimization=true, -Dio.netty.recycler.maxCapacityPerThread=0, -Dlog4j.shutdownHookEnabled=false, -Dlog4j2.disable.jmx=true, -XX:+HeapDumpOnOutOfMemoryError, -Des.path.home=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0, -Des.path.conf=/home/vagrant/src/Projects/ocr/elasticsearch-6.0.0/config]
[2017-12-02T20:41:42,840][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [aggs-matrix-stats]
[2017-12-02T20:41:42,841][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [analysis-common]
[2017-12-02T20:41:42,841][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [ingest-common]
[2017-12-02T20:41:42,842][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-expression]
[2017-12-02T20:41:42,842][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-mustache]
[2017-12-02T20:41:42,843][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [lang-painless]
[2017-12-02T20:41:42,845][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [parent-join]
[2017-12-02T20:41:42,845][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [percolator]
[2017-12-02T20:41:42,845][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [reindex]
[2017-12-02T20:41:42,849][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [repository-url]
[2017-12-02T20:41:42,850][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [transport-netty4]
[2017-12-02T20:41:42,850][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded module [tribe]
[2017-12-02T20:41:42,851][INFO ][o.e.p.PluginsService     ] [node-1_lindsay_01-dev] loaded plugin [ingest-attachment]
[2017-12-02T20:41:47,167][INFO ][o.e.d.DiscoveryModule    ] [node-1_lindsay_01-dev] using discovery type [zen]
[2017-12-02T20:41:49,118][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] initialized
[2017-12-02T20:41:49,119][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] starting ...
[2017-12-02T20:41:49,465][INFO ][o.e.t.TransportService   ] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2017-12-02T20:41:49,546][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] memory locking requested for elasticsearch process but memory is not locked
[2017-12-02T20:41:49,549][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max number of threads [3811] for user [vagrant] is too low, increase to at least [4096]
[2017-12-02T20:41:49,551][WARN ][o.e.b.BootstrapChecks    ] [node-1_lindsay_01-dev] max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144]
[2017-12-02T20:41:52,653][INFO ][o.e.c.s.MasterService    ] [node-1_lindsay_01-dev] zen-disco-elected-as-master ([0] nodes joined), reason: new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Gpc96YNRRDGJNFKL3hwbdA}{127.0.0.1}{127.0.0.1:9300}
[2017-12-02T20:41:52,664][INFO ][o.e.c.s.ClusterApplierService] [node-1_lindsay_01-dev] new_master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Gpc96YNRRDGJNFKL3hwbdA}{127.0.0.1}{127.0.0.1:9300}, reason: apply cluster state (from master [master {node-1_lindsay_01-dev}{K6il1mL8SgO_OsMykcPBjA}{Gpc96YNRRDGJNFKL3hwbdA}{127.0.0.1}{127.0.0.1:9300} committed version [1] source [zen-disco-elected-as-master ([0] nodes joined)]])
[2017-12-02T20:41:52,719][INFO ][o.e.h.n.Netty4HttpServerTransport] [node-1_lindsay_01-dev] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2017-12-02T20:41:52,721][INFO ][o.e.n.Node               ] [node-1_lindsay_01-dev] started
[2017-12-02T20:41:53,267][INFO ][o.e.g.GatewayService     ] [node-1_lindsay_01-dev] recovered [1] indices into cluster_state
[2017-12-02T20:41:55,284][INFO ][o.e.c.r.a.AllocationService] [node-1_lindsay_01-dev] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[documents][1]] ...]).
